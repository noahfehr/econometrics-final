{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ec636b-f361-4674-8c3e-c31a237e567e",
   "metadata": {},
   "source": [
    "# Importing AGORA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66a97ab5-5519-4be4-908d-a91c66e12707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "70a0be43-ede0-4ef6-b47a-a163d6d1ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('agora/documents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6b66b570-138e-4533-81a6-aaedd7c04aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This datasets consists of 650 AI-related bills in the USA.\n"
     ]
    }
   ],
   "source": [
    "print(f\"This datasets consists of {len(df)} AI-related bills in the USA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "703183e8-57a0-4eb8-9ae9-00b42feded9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_full_text(agora_id):\n",
    "    text = None\n",
    "    try:\n",
    "        with open(f'agora/fulltext/{agora_id}.txt', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0baf1dd2-fc7d-45f2-8aba-32131bd5d94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'agora/fulltext/207.txt'\n",
      "[Errno 2] No such file or directory: 'agora/fulltext/494.txt'\n",
      "[Errno 2] No such file or directory: 'agora/fulltext/402.txt'\n",
      "[Errno 2] No such file or directory: 'agora/fulltext/29.txt'\n"
     ]
    }
   ],
   "source": [
    "df[\"full_text\"] = df[\"AGORA ID\"].apply(add_full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "58ebaf47-c9b2-4646-9dfe-1b5df0029fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a preview of the first 5 bills in the dataset for reference:\n",
      "\n",
      "   AGORA ID                                      Official name  \\\n",
      "0       444                              CREATE AI Act of 2023   \n",
      "1      1723  National Standard of the Peopleâ€™s Republic of ...   \n",
      "2      1721                              Idaho House Bill 2472   \n",
      "3       281  A Bill in the District of Columbia to prohibit...   \n",
      "4       175  Limited Applicability of Consumer Financial Pr...   \n",
      "\n",
      "                                         Casual name  \\\n",
      "0                                                NaN   \n",
      "1  Basic Safety Requirements for Generative Artif...   \n",
      "2  Idaho HB 2472 (Managed Care Reform and Patient...   \n",
      "3      Stop Discrimination by Algorithms Act of 2023   \n",
      "4  Limited Applicability of Consumer Financial Pr...   \n",
      "\n",
      "                                    Link to document  \\\n",
      "0  https://www.congress.gov/bill/118th-congress/s...   \n",
      "1  https://cset.georgetown.edu/wp-content/uploads...   \n",
      "2  https://www.ilga.gov/legislation/BillStatus.as...   \n",
      "3  https://lims.dccouncil.gov/downloads/LIMS/5228...   \n",
      "4  https://www.federalregister.gov/documents/2022...   \n",
      "\n",
      "                              Authority  \\\n",
      "0                United States Congress   \n",
      "1                     Other authorities   \n",
      "2                                 Idaho   \n",
      "3                  District of Columbia   \n",
      "4  Consumer Financial Protection Bureau   \n",
      "\n",
      "                                         Collections Most recent activity  \\\n",
      "0                                  U.S. federal laws             Proposed   \n",
      "1                             Chinese law and policy             Proposed   \n",
      "2                          U.S. state and local laws              Enacted   \n",
      "3                          U.S. state and local laws             Proposed   \n",
      "4  U.S. regulations, executive orders, and agency...              Enacted   \n",
      "\n",
      "  Most recent activity date Proposed date  Annotated?  ...  \\\n",
      "0                2023-07-27    2023-07-27       False  ...   \n",
      "1                2024-05-17    2024-05-17       False  ...   \n",
      "2                2024-07-19    2023-02-15       False  ...   \n",
      "3                2023-02-10    2023-02-02        True  ...   \n",
      "4                2022-08-17           NaN        True  ...   \n",
      "\n",
      "   Strategies: New institution  Strategies: Performance requirements  \\\n",
      "0                        False                                 False   \n",
      "1                        False                                 False   \n",
      "2                        False                                 False   \n",
      "3                        False                                  True   \n",
      "4                        False                                  True   \n",
      "\n",
      "   Strategies: Pilots and testbeds Strategies: Tiering  \\\n",
      "0                            False               False   \n",
      "1                            False               False   \n",
      "2                            False               False   \n",
      "3                            False                True   \n",
      "4                            False               False   \n",
      "\n",
      "  Strategies: Tiering: Tiering based on domain of application  \\\n",
      "0                                              False            \n",
      "1                                              False            \n",
      "2                                              False            \n",
      "3                                              False            \n",
      "4                                              False            \n",
      "\n",
      "  Strategies: Tiering: Tiering based on generality  \\\n",
      "0                                            False   \n",
      "1                                            False   \n",
      "2                                            False   \n",
      "3                                            False   \n",
      "4                                            False   \n",
      "\n",
      "   Strategies: Tiering: Tiering based on impact  \\\n",
      "0                                         False   \n",
      "1                                         False   \n",
      "2                                         False   \n",
      "3                                         False   \n",
      "4                                         False   \n",
      "\n",
      "  Strategies: Tiering: Tiering based on inputs  \\\n",
      "0                                        False   \n",
      "1                                        False   \n",
      "2                                        False   \n",
      "3                                        False   \n",
      "4                                        False   \n",
      "\n",
      "  Strategies: Tiering: Tiering based on planning ability  \\\n",
      "0                                              False       \n",
      "1                                              False       \n",
      "2                                              False       \n",
      "3                                               True       \n",
      "4                                              False       \n",
      "\n",
      "                                           full_text  \n",
      "0  A BILL\\n\\nTo establish the National Artificial...  \n",
      "1  Cybersecurity Technology - Basic Safety Requir...  \n",
      "2      Section 30. The Managed Care Reform and Pa...  \n",
      "3  A BILL\\nIN THE COUNCIL OF THE DISTRICT OF COLU...  \n",
      "4  I. Background\\n\\nFinancial services companies ...  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Here is a preview of the first 5 bills in the dataset for reference:\\n\")\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "46c47ef2-40e3-419c-937c-c0a4dbc07c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('agora_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcc66fc-8044-4635-8a88-528b77b9ecf1",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fad0cc74-49e9-4f7d-b799-5e7f453d22a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('agora_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7fe65441-866c-4ebb-bf1a-331bcf6643e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/noahfehr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/noahfehr/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "from string import punctuation\n",
    "translator = str.maketrans('','',punctuation) \n",
    "from nltk.corpus import stopwords\n",
    "stoplist = set(stopwords.words('english'))\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cb2698ad-a6c0-45b0-ab8d-f67ac55383fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(doc):\n",
    "    \"Input doc and return clean list of tokens\"\n",
    "    doc = doc.replace('\\r', ' ').replace('\\n', ' ')\n",
    "    lower = doc.lower() # all lower case\n",
    "    nopunc = lower.translate(translator) # remove punctuation\n",
    "    words = nopunc.split() # split into tokens\n",
    "    nostop = [w for w in words if w not in stoplist] # remove stopwords\n",
    "    no_numbers = [w if not w.isdigit() else '#' for w in nostop] # normalize numbers\n",
    "    # stemmed = [stemmer.stem(w) for w in no_numbers] # stem each word\n",
    "    return no_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5bd4e3e9-68ab-492f-92fc-8916d43131cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(doc):\n",
    "    sent=[]\n",
    "    for raw in sent_tokenize(doc):\n",
    "        raw2 = normalize_text(raw)\n",
    "        sent.append(raw2)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d89b9fe-67c0-40aa-b4a0-1be9f67b8c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = list(df[\"full_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "498517cb-e485-4621-a4e0-d21a4d7a43c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for doc in sample:\n",
    "    try:\n",
    "        sentences += get_sentences(doc)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33231422-e30c-45ef-88dd-82bad9fb6a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "shuffle(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ce5f81ea-e033-4191-b815-0368332fd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "from gensim.models import Word2Vec\n",
    "w2v = Word2Vec(sentences,  # list of tokenized sentences\n",
    "               workers = 8, # Number of threads to run in parallel\n",
    "               vector_size=300,  # Word vector dimensionality     \n",
    "               min_count =  25, # Minimum word count  \n",
    "               window = 5, # Context window size      \n",
    "               sample = 1e-3, # Downsample setting for frequent words\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cde24350-ae21-4282-ba21-63b0feaa6586",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('legal_words.txt') as file:\n",
    "    common_law_terms = file.read()\n",
    "common_law_terms = common_law_terms.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "12b5cb0f-638f-49b8-8b85-d42834d75dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_law_similar = list()\n",
    "for term in common_law_terms:\n",
    "    try:\n",
    "        for similar_term, _ in w2v.wv.most_similar(term)[:5]:\n",
    "            common_law_similar.append(similar_term)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a43b779d-2a83-4ca1-9e65-f8904b6d056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_law_terms = common_law_terms + common_law_similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618e8db-ca90-4680-8620-9edeaa6151ed",
   "metadata": {},
   "source": [
    "# Pre-processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a9edb3d7-52d1-49b2-9616-861a664302f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/noahfehr/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/noahfehr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6ac26413-e772-44e6-b2f7-819406866af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        tokens = word_tokenize(text)\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in list(stop_words) + common_law_terms]\n",
    "        bigram = Phrases(tokens, min_count=5, threshold=10)\n",
    "        bigram_mod = Phraser(bigram)\n",
    "        tokens_with_bigrams = bigram_mod[tokens]\n",
    "        return ' '.join(tokens_with_bigrams)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "25dba4f0-0b46-41c2-a617-676b2db23d5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_text_preprocessed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(preprocess_text)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[84], line 8\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      6\u001b[0m stop_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      7\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(stop_words) \u001b[38;5;241m+\u001b[39m common_law_terms]\n\u001b[0;32m----> 8\u001b[0m bigram \u001b[38;5;241m=\u001b[39m Phrases(tokens, min_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      9\u001b[0m bigram_mod \u001b[38;5;241m=\u001b[39m Phraser(bigram)\n\u001b[1;32m     10\u001b[0m tokens_with_bigrams \u001b[38;5;241m=\u001b[39m bigram_mod[tokens]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/gensim/models/phrases.py:569\u001b[0m, in \u001b[0;36mPhrases.__init__\u001b[0;34m(self, sentences, min_count, threshold, max_vocab_size, delimiter, progress_per, scoring, connector_words)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sentences \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_vocab(sentences)\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m\"\u001b[39m, msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuilt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/gensim/models/phrases.py:648\u001b[0m, in \u001b[0;36mPhrases.add_vocab\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update model parameters with new `sentences`.\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m \n\u001b[1;32m    642\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;66;03m# Uses a separate vocab to collect the token counts from `sentences`.\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# This consumes more RAM than merging new sentences into `self.vocab`\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;66;03m# directly, but gives the new sentences a fighting chance to collect\u001b[39;00m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;66;03m# sufficient counts, before being pruned out by the (large) accumulated\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;66;03m# counts collected in previous learn_vocab runs.\u001b[39;00m\n\u001b[0;32m--> 648\u001b[0m min_reduce, vocab, total_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learn_vocab(\n\u001b[1;32m    649\u001b[0m     sentences, max_vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_vocab_size, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelimiter,\n\u001b[1;32m    650\u001b[0m     progress_per\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogress_per, connector_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnector_words,\n\u001b[1;32m    651\u001b[0m )\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_word_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total_words\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/gensim/models/phrases.py:596\u001b[0m, in \u001b[0;36mPhrases._learn_vocab\u001b[0;34m(sentences, max_vocab_size, delimiter, connector_words, progress_per)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    595\u001b[0m     phrase_tokens \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain([start_token], in_between, [word])\n\u001b[0;32m--> 596\u001b[0m     joined_phrase_token \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mjoin(phrase_tokens)\n\u001b[1;32m    597\u001b[0m     vocab[joined_phrase_token] \u001b[38;5;241m=\u001b[39m vocab\u001b[38;5;241m.\u001b[39mget(joined_phrase_token, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    598\u001b[0m start_token, in_between \u001b[38;5;241m=\u001b[39m word, []  \u001b[38;5;66;03m# treat word as both end of a phrase AND beginning of another\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df[\"full_text_preprocessed\"] = df[\"full_text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "014fb31c-7cdd-475a-956c-848130f850ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"agora_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0258f8fb-a218-44a8-826c-220b7a506fdb",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f33b6df-82e0-4bbb-ba08-844656194274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"agora_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9c89260-d62e-4d65-81aa-f8257bbae2b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer(max_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m, min_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m doc_term_matrix \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_text_preprocessed\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1369\u001b[0m             )\n\u001b[1;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1259\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1258\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m analyze(doc):\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:103\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chain together an optional series of text processing steps to go from\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03ma single document to ngrams, with or without tokenizing or preprocessing.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    A sequence of tokens, possibly with pairs, triples, etc.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     doc \u001b[38;5;241m=\u001b[39m decoder(doc)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     doc \u001b[38;5;241m=\u001b[39m analyzer(doc)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:236\u001b[0m, in \u001b[0;36m_VectorizerMixin.decode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    233\u001b[0m     doc \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_error)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan:\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.nan is an invalid document, expected byte or unicode string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=1000)\n",
    "doc_term_matrix = vectorizer.fit_transform(df[\"full_text_preprocessed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aeb85c92-178d-4fd3-a89b-7b695a68fd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ability', 'academia', 'academic', 'accelerate', 'access',\n",
       "       'accessible', 'accordance', 'account', 'accountability',\n",
       "       'accuracy', 'achieve', 'acquisition', 'across', 'acting', 'action',\n",
       "       'actions', 'activities', 'activity', 'actors', 'acts', 'actual',\n",
       "       'added', 'adding', 'addition', 'additional', 'address',\n",
       "       'administration', 'administrative', 'administrator', 'adopt',\n",
       "       'adoption', 'ads', 'advance', 'advanced', 'advancing', 'adverse',\n",
       "       'affairs', 'affect', 'affected', 'age', 'agencies', 'agency',\n",
       "       'agencys', 'agreement', 'agreements', 'agriculture', 'ai', 'air',\n",
       "       'aircraft', 'algorithm', 'algorithmic', 'algorithms', 'allow',\n",
       "       'alternative', 'amended', 'america', 'american', 'among', 'amount',\n",
       "       'amounts', 'analysis', 'annex', 'annual', 'another', 'applicable',\n",
       "       'applicant', 'application', 'applications', 'applied', 'apply',\n",
       "       'appointed', 'approach', 'approaches', 'appropriate',\n",
       "       'appropriated', 'appropriations', 'approval', 'approved', 'area',\n",
       "       'areas', 'armed', 'article', 'assembly', 'assess', 'assessment',\n",
       "       'assessments', 'assist', 'assistance', 'assistant', 'associated',\n",
       "       'atmospheric', 'attorney', 'audio', 'authorities', 'authority',\n",
       "       'authorization', 'authorized', 'automated', 'autonomous',\n",
       "       'availability', 'available', 'aviation', 'avoid', 'award',\n",
       "       'awards', 'based', 'basic', 'basis', 'beginning', 'behalf',\n",
       "       'benefit', 'benefits', 'best', 'better', 'bias', 'biological',\n",
       "       'biometric', 'board', 'bodies', 'body', 'border', 'budget',\n",
       "       'build', 'building', 'business', 'businesses', 'campaign',\n",
       "       'candidate', 'capabilities', 'capability', 'capable', 'capacity',\n",
       "       'care', 'carried', 'carry', 'carrying', 'case', 'cases',\n",
       "       'categories', 'cause', 'center', 'centers', 'certain',\n",
       "       'certification', 'chain', 'chains', 'chair', 'challenges',\n",
       "       'change', 'changes', 'chapter', 'characteristics', 'chief',\n",
       "       'child', 'children', 'china', 'circumstances', 'cited', 'civil',\n",
       "       'class', 'classification', 'classified', 'clear', 'clearly',\n",
       "       'cloud', 'code', 'collaboration', 'collected', 'collection',\n",
       "       'colleges', 'commerce', 'commercial', 'commission', 'committees',\n",
       "       'common', 'communication', 'communications', 'communities',\n",
       "       'companies', 'company', 'competent', 'competition', 'competitive',\n",
       "       'complete', 'compliance', 'comply', 'components', 'comprehensive',\n",
       "       'computational', 'computer', 'computing', 'concern', 'concerning',\n",
       "       'concerns', 'conditions', 'conduct', 'conducted', 'conducting',\n",
       "       'conformity', 'congress', 'congressional', 'consent', 'consider',\n",
       "       'consideration', 'considered', 'considers', 'consistent',\n",
       "       'consortium', 'construction', 'construed', 'consult',\n",
       "       'consultation', 'consumer', 'consumers', 'contact', 'containing',\n",
       "       'contains', 'content', 'contents', 'context', 'continue',\n",
       "       'contract', 'contracts', 'control', 'controlled', 'controls',\n",
       "       'cooperation', 'coordinate', 'coordination', 'cost', 'costs',\n",
       "       'could', 'council', 'countries', 'country', 'court', 'covered',\n",
       "       'create', 'created', 'creating', 'creation', 'credit', 'criminal',\n",
       "       'criteria', 'critical', 'current', 'customer', 'customers',\n",
       "       'cyber', 'cybersecurity', 'data', 'database', 'datasets', 'date',\n",
       "       'december', 'deceptive', 'decision', 'decisionmaking', 'decisions',\n",
       "       'deep', 'defense', 'defined', 'definition', 'definitions',\n",
       "       'definitionsin', 'degree', 'delivery', 'demonstrate',\n",
       "       'demonstration', 'department', 'departments', 'depiction',\n",
       "       'deployed', 'deployer', 'deployers', 'deployment', 'described',\n",
       "       'description', 'design', 'designated', 'designed', 'designee',\n",
       "       'detailed', 'detection', 'determination', 'determine',\n",
       "       'determined', 'develop', 'developed', 'developer', 'developers',\n",
       "       'developing', 'development', 'device', 'devices', 'different',\n",
       "       'digital', 'direct', 'directive', 'directly', 'director',\n",
       "       'disclose', 'disclosure', 'discrimination', 'dissemination',\n",
       "       'distributed', 'distribution', 'district', 'diverse', 'diversity',\n",
       "       'document', 'documentation', 'domestic', 'due', 'duties',\n",
       "       'economic', 'education', 'educational', 'effect', 'effective',\n",
       "       'effectively', 'effectiveness', 'effects', 'efficiency', 'efforts',\n",
       "       'eg', 'election', 'electronic', 'eligible', 'emergency',\n",
       "       'emerging', 'employee', 'employees', 'employer', 'employment',\n",
       "       'enable', 'enabling', 'enacted', 'encourage', 'end', 'energy',\n",
       "       'enforcement', 'engage', 'engaged', 'engagement', 'engineering',\n",
       "       'enhance', 'ensure', 'ensuring', 'enter', 'enterprises',\n",
       "       'entities', 'entity', 'environment', 'environmental',\n",
       "       'environments', 'equipment', 'equity', 'establish', 'established',\n",
       "       'establishing', 'establishment', 'et', 'etc', 'ethical', 'ethics',\n",
       "       'eu', 'european', 'evaluate', 'evaluation', 'evaluations', 'event',\n",
       "       'every', 'evidence', 'example', 'except', 'executive', 'existing',\n",
       "       'expand', 'expected', 'experience', 'expertise', 'experts',\n",
       "       'export', 'extent', 'external', 'facial', 'facilitate',\n",
       "       'facilities', 'facility', 'factors', 'federal', 'feedback',\n",
       "       'field', 'fields', 'final', 'financial', 'findings', 'fire',\n",
       "       'first', 'fiscal', 'five', 'focus', 'following', 'follows', 'food',\n",
       "       'force', 'foreign', 'form', 'forth', 'foundation', 'framework',\n",
       "       'frameworks', 'frontier', 'full', 'function', 'functions', 'fund',\n",
       "       'fundamental', 'funding', 'funds', 'future', 'gender', 'general',\n",
       "       'generalnot', 'generalpurpose', 'generalthe', 'generate',\n",
       "       'generated', 'generation', 'generative', 'given', 'global',\n",
       "       'goals', 'good', 'goods', 'governance', 'government',\n",
       "       'governments', 'grant', 'grants', 'greater', 'group', 'groups',\n",
       "       'guidance', 'guide', 'guidelines', 'hardware', 'harm', 'harmful',\n",
       "       'harms', 'head', 'heads', 'health', 'help', 'high', 'higher',\n",
       "       'highrisk', 'hiring', 'homeland', 'human', 'identifiable',\n",
       "       'identification', 'identified', 'identify', 'identifying',\n",
       "       'identity', 'image', 'images', 'impact', 'impacts', 'implement',\n",
       "       'implementation', 'implemented', 'implementing', 'important',\n",
       "       'improve', 'improving', 'include', 'included', 'includes',\n",
       "       'including', 'increase', 'independent', 'individual',\n",
       "       'individuals', 'industrial', 'industries', 'industry', 'influence',\n",
       "       'inform', 'information', 'infrastructure', 'initial', 'initiative',\n",
       "       'innovation', 'innovative', 'input', 'inserting', 'institute',\n",
       "       'institution', 'institutions', 'insurance', 'integrated',\n",
       "       'integration', 'integrity', 'intellectual', 'intelligent',\n",
       "       'intended', 'interagency', 'interest', 'interests', 'internal',\n",
       "       'international', 'internet', 'intimate', 'investigation',\n",
       "       'investment', 'involved', 'involving', 'issue', 'issued', 'issues',\n",
       "       'january', 'jurisdiction', 'key', 'knowledge', 'known', 'labor',\n",
       "       'laboratories', 'language', 'large', 'law', 'laws', 'lead',\n",
       "       'leadership', 'learning', 'least', 'legal', 'legislative', 'less',\n",
       "       'level', 'levels', 'leverage', 'liberties', 'life', 'lifecycle',\n",
       "       'like', 'likely', 'limitations', 'limited', 'list', 'listed',\n",
       "       'literacy', 'loan', 'local', 'located', 'machine', 'made',\n",
       "       'maintain', 'maintenance', 'major', 'make', 'makes', 'making',\n",
       "       'manage', 'management', 'managing', 'manner', 'manufacturing',\n",
       "       'many', 'market', 'material', 'materially', 'materials', 'matter',\n",
       "       'matters', 'meaning', 'means', 'measure', 'measures', 'mechanism',\n",
       "       'mechanisms', 'media', 'medical', 'meet', 'meeting', 'members',\n",
       "       'memorandum', 'mental', 'methods', 'metrics', 'military',\n",
       "       'minimum', 'mission', 'misuse', 'mitigate', 'mitigation', 'model',\n",
       "       'modeling', 'models', 'monitor', 'monitoring', 'months',\n",
       "       'multiple', 'nairr', 'name', 'national', 'natural', 'nature',\n",
       "       'necessary', 'needed', 'needs', 'network', 'networks', 'new',\n",
       "       'nonprofit', 'note', 'notice', 'notification', 'notified',\n",
       "       'nuclear', 'number', 'objectives', 'obligations', 'obtain',\n",
       "       'obtained', 'office', 'officer', 'officers', 'offices', 'official',\n",
       "       'officials', 'omb', 'one', 'ongoing', 'online', 'open',\n",
       "       'operating', 'operation', 'operational', 'operations', 'operator',\n",
       "       'operators', 'opportunities', 'opportunity', 'order',\n",
       "       'organization', 'organizations', 'others', 'otherwise', 'outcomes',\n",
       "       'output', 'outputs', 'overall', 'oversight', 'paragraph',\n",
       "       'paragraphs', 'part', 'participate', 'participation', 'particular',\n",
       "       'parties', 'partners', 'partnership', 'partnerships', 'party',\n",
       "       'patient', 'pay', 'payment', 'penalties', 'penalty', 'people',\n",
       "       'peoples', 'percent', 'perform', 'performance', 'period', 'person',\n",
       "       'personal', 'personnel', 'persons', 'physical', 'pilot', 'place',\n",
       "       'plan', 'planning', 'plans', 'platform', 'platforms', 'point',\n",
       "       'policies', 'policy', 'political', 'position', 'positions',\n",
       "       'possible', 'potential', 'power', 'powers', 'practicable',\n",
       "       'practice', 'practices', 'prescribed', 'president', 'prevent',\n",
       "       'primary', 'principles', 'prior', 'privacy', 'private',\n",
       "       'procedure', 'procedures', 'process', 'processes', 'processing',\n",
       "       'procurement', 'produced', 'product', 'production', 'products',\n",
       "       'professional', 'program', 'programs', 'progress', 'prohibited',\n",
       "       'prohibition', 'project', 'projects', 'promote', 'promoting',\n",
       "       'property', 'proposed', 'protect', 'protected', 'protection',\n",
       "       'protections', 'provenance', 'provide', 'provided', 'provider',\n",
       "       'providers', 'provides', 'providing', 'provision', 'provisions',\n",
       "       'public', 'publication', 'publicly', 'published', 'purpose',\n",
       "       'purposes', 'pursuant', 'qualified', 'quality', 'quantum',\n",
       "       'questions', 'range', 'rd', 'read', 'real', 'reasonable',\n",
       "       'reasonably', 'receive', 'received', 'recognition',\n",
       "       'recommendation', 'recommendations', 'record', 'records', 'reduce',\n",
       "       'reference', 'referred', 'regard', 'regarding', 'regulation',\n",
       "       'regulations', 'regulatory', 'related', 'relating', 'release',\n",
       "       'relevant', 'reliability', 'relief', 'report', 'reporting',\n",
       "       'reportnot', 'reports', 'representative', 'representatives',\n",
       "       'republic', 'request', 'requests', 'require', 'required',\n",
       "       'requirement', 'requirements', 'requires', 'research',\n",
       "       'researchers', 'resilience', 'resource', 'resources', 'respect',\n",
       "       'response', 'responsibilities', 'responsibility', 'responsible',\n",
       "       'result', 'results', 'review', 'right', 'rights', 'risk', 'risks',\n",
       "       'role', 'roles', 'rule', 'rules', 'safe', 'safeguards', 'safety',\n",
       "       'scale', 'school', 'science', 'sciences', 'scientific', 'scope',\n",
       "       'score', 'screening', 'sec', 'secretary', 'sections', 'sector',\n",
       "       'sectors', 'secure', 'security', 'seek', 'select', 'senior',\n",
       "       'sensitive', 'seq', 'serve', 'service', 'services', 'set', 'sets',\n",
       "       'sexual', 'share', 'shared', 'sharing', 'short', 'significant',\n",
       "       'similar', 'skills', 'small', 'smart', 'social', 'societal',\n",
       "       'society', 'software', 'solutions', 'source', 'sources', 'space',\n",
       "       'special', 'specific', 'specified', 'spectrum', 'speech', 'sports',\n",
       "       'staff', 'stakeholders', 'standard', 'standards', 'state',\n",
       "       'statement', 'status', 'stem', 'storage', 'strategic',\n",
       "       'strategies', 'strategy', 'strengthen', 'striking', 'structure',\n",
       "       'students', 'study', 'subdivision', 'subject', 'submission',\n",
       "       'submit', 'submitted', 'subsection', 'substantially', 'sufficient',\n",
       "       'summary', 'supply', 'support', 'supporting', 'surveillance',\n",
       "       'synthetic', 'system', 'systems', 'table', 'take', 'taken',\n",
       "       'taking', 'talent', 'task', 'tasks', 'team', 'teams', 'technical',\n",
       "       'techniques', 'technological', 'technologies', 'technology',\n",
       "       'term', 'terms', 'test', 'testing', 'text', 'thereof', 'third',\n",
       "       'threat', 'threats', 'throughout', 'time', 'timely', 'title',\n",
       "       'tool', 'tools', 'trade', 'train', 'training', 'transaction',\n",
       "       'transfer', 'transparency', 'transportation', 'treatment',\n",
       "       'tribal', 'trust', 'trustworthy', 'two', 'type', 'types',\n",
       "       'understand', 'understanding', 'union', 'unlawful', 'unless',\n",
       "       'unmanned', 'update', 'updated', 'upon', 'us', 'usc', 'use',\n",
       "       'used', 'user', 'users', 'uses', 'using', 'utilization',\n",
       "       'validation', 'value', 'vehicle', 'vehicles', 'vendor',\n",
       "       'verification', 'video', 'vii', 'violation', 'violations',\n",
       "       'visual', 'voice', 'voluntary', 'vulnerabilities', 'wagering',\n",
       "       'water', 'way', 'ways', 'weapon', 'weather', 'website', 'well',\n",
       "       'whole', 'whose', 'within', 'without', 'work', 'worker', 'workers',\n",
       "       'workforce', 'working', 'world', 'written', 'year', 'years'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d5eeb9c-ca2b-4fa2-8176-a19b68246889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 5, 0],\n",
       "       [5, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 6, 1, 1],\n",
       "       ...,\n",
       "       [2, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 3, 0]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4a41d75-2490-40da-87a8-2f9722c9b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 3\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics,\n",
    "    max_iter=200,\n",
    "    learning_method='online',\n",
    "    random_state=42,\n",
    "    batch_size=128,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c328e794-e34b-496d-9660-90a11054b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_output = lda.fit_transform(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b81865c-1dc5-4eee-9e16-8d471b56659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "276a323c-6cc8-4e6d-9a8e-9e3d79e910d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top words in each topic:\n",
      "\n",
      "Topic 1:\n",
      "information, covered, state, person, commission, means, including, individual, service, data\n",
      "\n",
      "Topic 2:\n",
      "ai, systems, data, use, system, risks, security, development, including, safety\n",
      "\n",
      "Topic 3:\n",
      "secretary, national, including, subsection, director, research, technology, program, defense, paragraph\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop words in each topic:\")\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    top_words_idx = topic.argsort()[:-10-1:-1]\n",
    "    top_words = [feature_names[i] for i in top_words_idx]\n",
    "    print(f\"\\nTopic {topic_idx + 1}:\")\n",
    "    print(\", \".join(top_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c93ba190-0a50-4a98-9e21-b6c8ad761144",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_columns = [f'Topic_{i+1}' for i in range(n_topics)]\n",
    "df_topics = pd.DataFrame(lda_output, columns=topic_columns)\n",
    "df = pd.concat([df, df_topics], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ae27df1-faec-484a-a9bb-0fc5b22fd151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example documents for each topic:\n",
      "\n",
      "Top documents for Topic 1:\n",
      "\\Text: enacted state utah b amended read b definitions used chapter child sexual abuse material means visual depiction including live performance photograph film video picture computer computergenerated imag...\n",
      "Topic 1 probability: 0.999\n",
      "\\Text: relating elections amending enacting sections campaign reporting adding disclaimer requirements advertisements containing materially deceptive media creating crime distributing entering agreement anot...\n",
      "Topic 1 probability: 0.999\n",
      "\\Text: short title cited tools address known exploitation immobilizing technological deepfakes websites networks take sec criminal prohibition intentional disclosure nonconsensual intimate visual depictions ...\n",
      "Topic 1 probability: 0.999\n",
      "\n",
      "Top documents for Topic 2:\n",
      "\\Text: hiroshima process international code conduct organizations developing advanced ai systems basis international guiding principles organizations developing advanced ai systems international code conduct...\n",
      "Topic 2 probability: 0.999\n",
      "\\Text: background tangible global leadership european union provide scalable sciencebased methods advance trustworthy approaches ai serve people responsible equitable beneficial ways effective risk managemen...\n",
      "Topic 2 probability: 0.999\n",
      "\\Text: general assembly opening declarations omitted resolves bridge digital divides within countries resolves promote safe secure trustworthy systems accelerate progress towards full realization agenda sust...\n",
      "Topic 2 probability: 0.999\n",
      "\n",
      "Top documents for Topic 3:\n",
      "\\Text: sec strengthening mobility revolutionizing transportation grant program definitionsin eligible entitythe term eligible entity means state b political subdivision state c tribal government public trans...\n",
      "Topic 3 probability: 0.999\n",
      "\\Text: promote leadership technical standards directing national institute standards technology department state take certain actions encourage enable participation developing standards specifications critic...\n",
      "Topic 3 probability: 0.999\n",
      "\\Text: sec centers excellence food agriculture conservation trade usc amended striking subsections b c inserting following centers excellence generalthe secretary agriculture establish least one center excel...\n",
      "Topic 3 probability: 0.998\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExample documents for each topic:\")\n",
    "for topic_idx in range(n_topics):\n",
    "    print(f\"\\nTop documents for Topic {topic_idx + 1}:\")\n",
    "    top_docs = df.nlargest(3, f'Topic_{topic_idx+1}')\n",
    "    for idx, row in top_docs.iterrows():\n",
    "        print(f\"\\Text: {row['full_text_preprocessed'][:200]}...\")\n",
    "        print(f\"Topic {topic_idx + 1} probability: {row[f'Topic_{topic_idx+1}']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef2ab5-44dd-435c-8e51-29d7c8fc4c4b",
   "metadata": {},
   "source": [
    "### BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22cd14ea-e9c1-43ea-9af1-909c2a8ff785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emilx\\anaconda3\\envs\\nlp_lss\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "485eee2a-6b9a-4543-8425-0ef17b89ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=20, metric='euclidean', prediction_data=True)\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    min_topic_size=10,     # Merges tiny topics into larger ones, when set to 20 only 2 topics\n",
    "    verbose=True,\n",
    "    calculate_probabilities=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abdbdad7-5e8d-4638-b6fc-fc4d12a83541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 12:20:26,124 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:27<00:00,  4.14s/it]\n",
      "2025-05-28 12:21:54,834 - BERTopic - Embedding - Completed âœ“\n",
      "2025-05-28 12:21:54,837 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-05-28 12:21:58,363 - BERTopic - Dimensionality - Completed âœ“\n",
      "2025-05-28 12:21:58,366 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-05-28 12:21:58,557 - BERTopic - Cluster - Completed âœ“\n",
      "2025-05-28 12:21:58,572 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2025-05-28 12:22:00,691 - BERTopic - Representation - Completed âœ“\n"
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.fit_transform(df['full_text_preprocessed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8984981-4e57-4e50-aab2-5af9bec8c9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top words for each topic:\n",
      "\n",
      "Topic 0:\n",
      "defense, education, director, program, research, secretary, subsection, national, including, paragraph\n",
      "\n",
      "Topic 1:\n",
      "ai, systems, system, data, use, article, security, risks, model, development\n",
      "\n",
      "Topic 2:\n",
      "energy, research, secretary, national, program, including, weather, development, technologies, data\n",
      "\n",
      "Topic 3:\n",
      "person, individual, election, media, image, audio, means, visual, sexual, video\n",
      "\n",
      "Topic 4:\n",
      "automated, system, data, decision, information, use, state, employer, used, systems\n",
      "\n",
      "Topic 5:\n",
      "covered, foreign, entity, president, secretary, security, regulations, term, national, activity\n",
      "\n",
      "Topic 6:\n",
      "health, care, plan, services, medical, patient, ai, use, program, benefits\n",
      "\n",
      "Topic 7:\n",
      "commission, agency, council, data, digital, criticalimpact, chief, government, state, including\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop words for each topic:\")\n",
    "for topic_id in topic_model.get_topics():\n",
    "    if topic_id != -1:  # Skip the outlier topic (-1)\n",
    "        words = topic_model.get_topic(topic_id)\n",
    "        print(f\"\\nTopic {topic_id}:\")\n",
    "        print(\", \".join([word for word, _ in words[:10]]))  # Show top 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cef1eca-5d54-414b-9041-382fb256af66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m BERT_probs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(probs, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBERT_topic0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBERT_topic1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBERT_topic2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBERT_topic3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBERT_topic4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBERT_topic5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBERT_topic6\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBERT_topic7\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, BERT_probs], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'probs' is not defined"
     ]
    }
   ],
   "source": [
    "BERT_probs = pd.DataFrame(probs, columns=['BERT_topic0', 'BERT_topic1', 'BERT_topic2', 'BERT_topic3', 'BERT_topic4', 'BERT_topic5', 'BERT_topic6', 'BERT_topic7'])\n",
    "df = pd.concat([df, BERT_probs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1b85e18c-448e-463e-90a9-41c7499eb07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,   9,  20,  22,  25,  26,  34,  35,  36,  37,  38,  39,  40,\n",
       "        41,  42,  43,  44,  45,  53,  54,  56,  82,  83,  91,  92,  93,\n",
       "       101, 105, 107, 116, 117, 123, 132, 137, 143, 149, 167, 174, 175,\n",
       "       176, 178, 180, 181, 182, 183, 184, 185, 187, 188, 189, 195, 198,\n",
       "       210, 218, 220, 222, 225, 229, 232, 234, 238, 239, 243, 246, 248,\n",
       "       251, 252, 253, 261, 269, 271, 272, 283, 290, 291, 293, 296, 297,\n",
       "       298, 301, 302, 306, 307, 310, 315, 316, 317, 318, 321, 324, 325,\n",
       "       337, 340, 341, 343, 344, 353, 357, 358, 361, 373, 374, 381, 386,\n",
       "       390, 399, 400, 402, 411, 414, 416, 417, 423, 425, 427, 430, 432,\n",
       "       437, 442, 443, 448, 450, 452, 454, 456, 460, 462, 464, 467, 470,\n",
       "       472, 474, 476, 478, 479, 486, 488, 490, 495, 498, 499, 502, 503,\n",
       "       504, 505, 507, 508, 509, 514, 515, 516, 517, 518, 519, 527, 532,\n",
       "       533, 534, 535, 537, 547, 548, 552, 554, 555, 558, 559, 566, 568,\n",
       "       569, 570, 582, 583, 584, 585, 586, 588, 589, 600, 602, 605, 606,\n",
       "       611, 613, 614, 615, 616, 617, 618, 621, 623, 641, 645, 646, 647],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_topic_indices = np.where(np.array(topics) == -1)[0]\n",
    "dummy_topic_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d150819-3491-4925-892d-d33c7cfb2006",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(dummy_topic_indices)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "20fa6756-3381-4c02-914c-b2128df1124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('agora_topic_probabilities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b32e2f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States Congress' 'Other authorities' 'Idaho'\n",
      " 'District of Columbia' 'Government of Israel' 'Government of New Zealand'\n",
      " 'United Nations' 'California' 'Illinois' 'Utah' 'Arizona'\n",
      " 'Other multinational' 'Indiana' 'Mississippi' 'New York' 'West Virginia'\n",
      " 'Tennessee' 'European Union' 'Chinese central government'\n",
      " 'Private-sector companies' 'Executive Office of the President' 'Colorado'\n",
      " 'Washington' 'Nebraska' 'Maryland'\n",
      " 'Chinese provincial and local governments' 'Government of Canada'\n",
      " 'South Dakota' 'Alabama' 'New Hampshire' 'Connecticut' 'Oregon' 'Hawaii'\n",
      " 'Iowa' 'Florida' 'Louisiana' 'Department of Defense'\n",
      " 'Government of Australia' 'Office of Management and Budget' 'Wisconsin'\n",
      " 'New Mexico' 'Minnesota' 'Michigan'\n",
      " 'National Institute of Standards and Technology'\n",
      " 'Government of the United Kingdom' 'Department of Commerce'\n",
      " 'Federal Election Commission' 'OECD' 'Texas' 'Massachusetts'\n",
      " 'Rhode Island' 'Arkansas' 'Virginia' 'New Jersey' 'North Carolina'\n",
      " 'Pennsylvania' 'Copyright Office, Library of Congress' 'North Dakota'\n",
      " 'South Carolina' 'Department of Agriculture'\n",
      " 'Department of Health and Human Services' 'Department of Education']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gov_category\n",
       "federal_legislative     294\n",
       "federal_executive        19\n",
       "California               14\n",
       "New York                  9\n",
       "New Jersey                4\n",
       "Utah                      4\n",
       "Arizona                   3\n",
       "Massachusetts             3\n",
       "Tennessee                 3\n",
       "Pennsylvania              3\n",
       "Idaho                     3\n",
       "New Hampshire             3\n",
       "Rhode Island              2\n",
       "Alabama                   2\n",
       "Texas                     2\n",
       "Michigan                  2\n",
       "Florida                   2\n",
       "Hawaii                    2\n",
       "Connecticut               2\n",
       "Colorado                  2\n",
       "Illinois                  2\n",
       "Indiana                   2\n",
       "Mississippi               2\n",
       "West Virginia             1\n",
       "North Dakota              1\n",
       "District of Columbia      1\n",
       "North Carolina            1\n",
       "Virginia                  1\n",
       "Arkansas                  1\n",
       "South Dakota              1\n",
       "Maryland                  1\n",
       "Minnesota                 1\n",
       "New Mexico                1\n",
       "Wisconsin                 1\n",
       "Louisiana                 1\n",
       "Washington                1\n",
       "Iowa                      1\n",
       "Nebraska                  1\n",
       "Oregon                    1\n",
       "South Carolina            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('intermediate_data/agora_topic_probabilities.csv')\n",
    "cols_to_drop = [\n",
    "    'Unnamed: 0', 'AGORA ID', 'Official name', 'Casual name', 'Link to document', 'Collections',\n",
    "    'full_text_preprocessed', 'full_text', 'Tags', 'Short summary', 'Long summary', 'Summaries and tags may include unreviewed machine output',\n",
    "    'Official plaintext retrieved', 'Official plaintext source', 'Official plaintext unavailable/infeasible', 'Official pdf source', 'Official pdf retrieved'\n",
    "]\n",
    "df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "print(df['Authority'].unique())\n",
    "\n",
    "authorities_to_drop = [\n",
    "    'Government of Israel', 'Government of New Zealand', 'Government of Canada',\n",
    "    'Government of Australia', 'Government of the United Kingdom',\n",
    "    'Chinese central government', 'Chinese provincial and local governments',\n",
    "    'European Union', 'United Nations', 'OECD', 'Other multinational'\n",
    "]\n",
    "df = df[~df['Authority'].isin(authorities_to_drop)]\n",
    "\n",
    "federal_legislative = ['United States Congress']\n",
    "federal_executive = [\n",
    "    'Executive Office of the President', 'Department of Defense',\n",
    "    'Department of Commerce', 'Department of Agriculture',\n",
    "    'Department of Health and Human Services', 'Department of Education',\n",
    "    'Office of Management and Budget', 'Federal Election Commission',\n",
    "    'National Institute of Standards and Technology',\n",
    "    'Copyright Office, Library of Congress'\n",
    "]\n",
    "us_states = [\n",
    "    'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado',\n",
    "    'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho',\n",
    "    'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana',\n",
    "    'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
    "    'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
    "    'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
    "    'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n",
    "    'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n",
    "    'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
    "    'West Virginia', 'Wisconsin', 'Wyoming', 'District of Columbia'\n",
    "]\n",
    "def categorize(entity):\n",
    "    if entity in federal_legislative:\n",
    "        return 'federal_legislative'\n",
    "    elif entity in federal_executive:\n",
    "        return 'federal_executive'\n",
    "    elif entity in us_states:\n",
    "        return entity\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "df['gov_category'] = df['Authority'].apply(categorize)\n",
    "df = df[df['gov_category'].notna()]\n",
    "df['gov_category'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9e92de92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gov_category_consolidated\n",
       "federal_legislative    294\n",
       "blue_state              48\n",
       "red_state               26\n",
       "federal_executive       19\n",
       "purple_state            14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue_states = [\n",
    "    'California', 'Connecticut', 'Delaware', 'Hawaii', 'Illinois', 'Maine',\n",
    "    'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'New Jersey',\n",
    "    'New Mexico', 'New York', 'Oregon', 'Rhode Island', 'Vermont',\n",
    "    'Washington', 'Colorado', 'Nevada', 'District of Columbia'\n",
    "]\n",
    "\n",
    "red_states = [\n",
    "    'Alabama', 'Arkansas', 'Idaho', 'Indiana', 'Iowa', 'Kansas', 'Kentucky',\n",
    "    'Louisiana', 'Mississippi', 'Missouri', 'Montana', 'Nebraska',\n",
    "    'North Dakota', 'Oklahoma', 'South Carolina', 'South Dakota',\n",
    "    'Tennessee', 'Texas', 'Utah', 'West Virginia', 'Wyoming'\n",
    "]\n",
    "\n",
    "purple_states = [\n",
    "    'Arizona', 'Florida', 'Georgia', 'New Hampshire', 'North Carolina',\n",
    "    'Ohio', 'Pennsylvania', 'Virginia', 'Wisconsin'  \n",
    "]\n",
    "\n",
    "def color_label(entity):\n",
    "    if entity in blue_states:\n",
    "        return 'blue_state'\n",
    "    elif entity in red_states:\n",
    "        return 'red_state'\n",
    "    elif entity in purple_states:\n",
    "        return 'purple_state'\n",
    "    else:\n",
    "        return entity \n",
    "\n",
    "df['gov_category_consolidated'] = df['gov_category'].apply(color_label)\n",
    "df['gov_category_consolidated'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0b7c5173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Most recent activity date', 'Annotated?',\n",
       "       'Primarily applies to the government',\n",
       "       'Primarily applies to the private sector', 'Number of segments created',\n",
       "       'Applications: Agriculture and resource extraction',\n",
       "       'Applications: Arts, sports, leisure, travel, and lifestyle',\n",
       "       'Applications: Broadcasting and media production',\n",
       "       'Applications: Business services and analytics',\n",
       "       'Applications: Construction and field services',\n",
       "       'Applications: Consumer goods', 'Applications: Education',\n",
       "       'Applications: Energy and utilities',\n",
       "       'Applications: Finance and investment',\n",
       "       'Applications: Government: benefits and welfare',\n",
       "       'Applications: Government: judicial and law enforcement',\n",
       "       'Applications: Government: military and public safety',\n",
       "       'Applications: Government: other applications/unspecified',\n",
       "       'Applications: Manufacturing and process automation',\n",
       "       'Applications: Medicine, life sciences and public health',\n",
       "       'Applications: Networking and telecommunications',\n",
       "       'Applications: Sales, retail, and customer relations',\n",
       "       'Applications: Security', 'Applications: Transportation',\n",
       "       'Harms: Detrimental content', 'Harms: Discrimination',\n",
       "       'Harms: Ecological harm', 'Harms: Financial loss',\n",
       "       'Harms: Harm to health/safety', 'Harms: Harm to infrastructure',\n",
       "       'Harms: Harm to property',\n",
       "       'Harms: Violation of civil or human rights, including privacy',\n",
       "       'Incentives: Access to business opportunities',\n",
       "       'Incentives: Civil liability', 'Incentives: Criminal liability',\n",
       "       'Incentives: Fines', 'Incentives: Imprisonment',\n",
       "       'Incentives: Subsidies', 'Risk factors: Bias',\n",
       "       'Risk factors: Interpretability and explainability',\n",
       "       'Risk factors: Privacy', 'Risk factors: Reliability',\n",
       "       'Risk factors: Reliability: Robustness', 'Risk factors: Safety',\n",
       "       'Risk factors: Security', 'Risk factors: Security: Cybersecurity',\n",
       "       'Risk factors: Security: Dissemination', 'Risk factors: Transparency',\n",
       "       'Strategies: Convening', 'Strategies: Disclosure',\n",
       "       'Strategies: Disclosure: About evaluation',\n",
       "       'Strategies: Disclosure: About incidents',\n",
       "       'Strategies: Disclosure: About inputs',\n",
       "       'Strategies: Disclosure: Accuracy thereof',\n",
       "       'Strategies: Disclosure: In deployment',\n",
       "       'Strategies: Disclosure: In standard form', 'Strategies: Evaluation',\n",
       "       'Strategies: Evaluation: Adversarial testing',\n",
       "       'Strategies: Evaluation: Conformity assessment',\n",
       "       'Strategies: Evaluation: External auditing',\n",
       "       'Strategies: Evaluation: Impact assessment',\n",
       "       'Strategies: Evaluation: Post-market monitoring',\n",
       "       'Strategies: Governance development',\n",
       "       'Strategies: Government study or report',\n",
       "       'Strategies: Government support',\n",
       "       'Strategies: Government support: AI workforce-related',\n",
       "       'Strategies: Government support: For R&D', 'Strategies: Input controls',\n",
       "       'Strategies: Input controls: Compute circulation',\n",
       "       'Strategies: Input controls: Compute use',\n",
       "       'Strategies: Input controls: Data circulation',\n",
       "       'Strategies: Input controls: Data use',\n",
       "       'Strategies: Licensing, registration, and certification',\n",
       "       'Strategies: New institution', 'Strategies: Performance requirements',\n",
       "       'Strategies: Pilots and testbeds', 'Strategies: Tiering',\n",
       "       'Strategies: Tiering: Tiering based on domain of application',\n",
       "       'Strategies: Tiering: Tiering based on generality',\n",
       "       'Strategies: Tiering: Tiering based on impact',\n",
       "       'Strategies: Tiering: Tiering based on inputs',\n",
       "       'Strategies: Tiering: Tiering based on planning ability', 'BERT_topic0',\n",
       "       'BERT_topic1', 'BERT_topic2', 'BERT_topic3', 'BERT_topic4',\n",
       "       'BERT_topic5', 'BERT_topic6', 'BERT_topic7',\n",
       "       'gov_category_consolidated', 'enacted_binary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Authority', 'LDA_topic1',\n",
    "       'LDA_topic2', 'LDA_topic3','gov_category'], errors='ignore')\n",
    "\n",
    "df = df.drop(columns=['Proposed date'], errors='ignore')\n",
    "df['enacted_binary'] = (df['Most recent activity'] == 'Enacted').astype(int)\n",
    "df = df.drop(columns=['Most recent activity', 'Validated?'], errors='ignore')\n",
    "df.columns\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "75ed1d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enacted_binary\n",
       "0    229\n",
       "1    172\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate the column you want to exclude\n",
    "date_col = df[['Most recent activity date']]\n",
    "\n",
    "# Apply get_dummies to the rest\n",
    "df_encoded = pd.get_dummies(df.drop(columns=['Most recent activity date']))\n",
    "\n",
    "# Concatenate back the excluded column\n",
    "df = pd.concat([df_encoded, date_col], axis=1)\n",
    "# Convert all bool columns to 0/1 integers\n",
    "for col in df_encoded.select_dtypes(include='bool').columns:\n",
    "    df_encoded[col] = df_encoded[col].astype(int)\n",
    "df = pd.concat([df_encoded, date_col], axis=1)\n",
    "df['enacted_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d17bc3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Annotated?', 'Primarily applies to the government',\n",
       "       'Primarily applies to the private sector', 'Number of segments created',\n",
       "       'Applications: Agriculture and resource extraction',\n",
       "       'Applications: Arts, sports, leisure, travel, and lifestyle',\n",
       "       'Applications: Broadcasting and media production',\n",
       "       'Applications: Business services and analytics',\n",
       "       'Applications: Construction and field services',\n",
       "       'Applications: Consumer goods', 'Applications: Education',\n",
       "       'Applications: Energy and utilities',\n",
       "       'Applications: Finance and investment',\n",
       "       'Applications: Government: benefits and welfare',\n",
       "       'Applications: Government: judicial and law enforcement',\n",
       "       'Applications: Government: military and public safety',\n",
       "       'Applications: Government: other applications/unspecified',\n",
       "       'Applications: Manufacturing and process automation',\n",
       "       'Applications: Medicine, life sciences and public health',\n",
       "       'Applications: Networking and telecommunications',\n",
       "       'Applications: Sales, retail, and customer relations',\n",
       "       'Applications: Security', 'Applications: Transportation',\n",
       "       'Harms: Detrimental content', 'Harms: Discrimination',\n",
       "       'Harms: Ecological harm', 'Harms: Financial loss',\n",
       "       'Harms: Harm to health/safety', 'Harms: Harm to infrastructure',\n",
       "       'Harms: Harm to property',\n",
       "       'Harms: Violation of civil or human rights, including privacy',\n",
       "       'Incentives: Access to business opportunities',\n",
       "       'Incentives: Civil liability', 'Incentives: Criminal liability',\n",
       "       'Incentives: Fines', 'Incentives: Imprisonment',\n",
       "       'Incentives: Subsidies', 'Risk factors: Bias',\n",
       "       'Risk factors: Interpretability and explainability',\n",
       "       'Risk factors: Privacy', 'Risk factors: Reliability',\n",
       "       'Risk factors: Reliability: Robustness', 'Risk factors: Safety',\n",
       "       'Risk factors: Security', 'Risk factors: Security: Cybersecurity',\n",
       "       'Risk factors: Security: Dissemination', 'Risk factors: Transparency',\n",
       "       'Strategies: Convening', 'Strategies: Disclosure',\n",
       "       'Strategies: Disclosure: About evaluation',\n",
       "       'Strategies: Disclosure: About incidents',\n",
       "       'Strategies: Disclosure: About inputs',\n",
       "       'Strategies: Disclosure: Accuracy thereof',\n",
       "       'Strategies: Disclosure: In deployment',\n",
       "       'Strategies: Disclosure: In standard form', 'Strategies: Evaluation',\n",
       "       'Strategies: Evaluation: Adversarial testing',\n",
       "       'Strategies: Evaluation: Conformity assessment',\n",
       "       'Strategies: Evaluation: External auditing',\n",
       "       'Strategies: Evaluation: Impact assessment',\n",
       "       'Strategies: Evaluation: Post-market monitoring',\n",
       "       'Strategies: Governance development',\n",
       "       'Strategies: Government study or report',\n",
       "       'Strategies: Government support',\n",
       "       'Strategies: Government support: AI workforce-related',\n",
       "       'Strategies: Government support: For R&D', 'Strategies: Input controls',\n",
       "       'Strategies: Input controls: Compute circulation',\n",
       "       'Strategies: Input controls: Compute use',\n",
       "       'Strategies: Input controls: Data circulation',\n",
       "       'Strategies: Input controls: Data use',\n",
       "       'Strategies: Licensing, registration, and certification',\n",
       "       'Strategies: New institution', 'Strategies: Performance requirements',\n",
       "       'Strategies: Pilots and testbeds', 'Strategies: Tiering',\n",
       "       'Strategies: Tiering: Tiering based on domain of application',\n",
       "       'Strategies: Tiering: Tiering based on generality',\n",
       "       'Strategies: Tiering: Tiering based on impact',\n",
       "       'Strategies: Tiering: Tiering based on inputs',\n",
       "       'Strategies: Tiering: Tiering based on planning ability', 'BERT_topic0',\n",
       "       'BERT_topic1', 'BERT_topic2', 'BERT_topic3', 'BERT_topic4',\n",
       "       'BERT_topic5', 'BERT_topic6', 'BERT_topic7', 'enacted_binary',\n",
       "       'gov_category_consolidated_blue_state',\n",
       "       'gov_category_consolidated_federal_executive',\n",
       "       'gov_category_consolidated_federal_legislative',\n",
       "       'gov_category_consolidated_purple_state',\n",
       "       'gov_category_consolidated_red_state', 'Most recent activity date',\n",
       "       'datedummy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate days after 2019-02-11 for each date in 'Most recent activity date'\n",
    "df['datedummy'] = (df['Most recent activity date'].astype('datetime64[ns]') - pd.to_datetime('2019-02-11')).dt.days\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "defefc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primarily applies to the government</th>\n",
       "      <th>Primarily applies to the private sector</th>\n",
       "      <th>Applications: Agriculture and resource extraction</th>\n",
       "      <th>Applications: Arts, sports, leisure, travel, and lifestyle</th>\n",
       "      <th>Applications: Broadcasting and media production</th>\n",
       "      <th>Applications: Business services and analytics</th>\n",
       "      <th>Applications: Construction and field services</th>\n",
       "      <th>Applications: Consumer goods</th>\n",
       "      <th>Applications: Education</th>\n",
       "      <th>Applications: Energy and utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>BERT_topic5</th>\n",
       "      <th>BERT_topic6</th>\n",
       "      <th>BERT_topic7</th>\n",
       "      <th>enacted_binary</th>\n",
       "      <th>gov_category_consolidated_blue_state</th>\n",
       "      <th>gov_category_consolidated_federal_executive</th>\n",
       "      <th>gov_category_consolidated_federal_legislative</th>\n",
       "      <th>gov_category_consolidated_purple_state</th>\n",
       "      <th>gov_category_consolidated_red_state</th>\n",
       "      <th>datedummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.493676e-01</td>\n",
       "      <td>7.192617e-02</td>\n",
       "      <td>1.225086e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.251081e-308</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.897701e-308</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.766464e-02</td>\n",
       "      <td>3.240372e-02</td>\n",
       "      <td>3.911828e-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.692844e-02</td>\n",
       "      <td>5.720213e-02</td>\n",
       "      <td>6.529173e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.029906e-308</td>\n",
       "      <td>2.304330e-308</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.847546e-02</td>\n",
       "      <td>3.780430e-02</td>\n",
       "      <td>9.176968e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.031788e-01</td>\n",
       "      <td>5.254648e-02</td>\n",
       "      <td>1.384755e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.205962e-01</td>\n",
       "      <td>6.213679e-02</td>\n",
       "      <td>1.266515e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.266922e-01</td>\n",
       "      <td>7.054527e-02</td>\n",
       "      <td>1.175328e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.311128e-02</td>\n",
       "      <td>3.800437e-02</td>\n",
       "      <td>9.262109e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Primarily applies to the government  \\\n",
       "0                                      0   \n",
       "2                                      0   \n",
       "3                                      0   \n",
       "7                                      0   \n",
       "8                                      0   \n",
       "..                                   ...   \n",
       "450                                    1   \n",
       "451                                    1   \n",
       "452                                    1   \n",
       "453                                    1   \n",
       "454                                    1   \n",
       "\n",
       "     Primarily applies to the private sector  \\\n",
       "0                                          0   \n",
       "2                                          0   \n",
       "3                                          1   \n",
       "7                                          0   \n",
       "8                                          0   \n",
       "..                                       ...   \n",
       "450                                        0   \n",
       "451                                        0   \n",
       "452                                        0   \n",
       "453                                        0   \n",
       "454                                        0   \n",
       "\n",
       "     Applications: Agriculture and resource extraction  \\\n",
       "0                                                    0   \n",
       "2                                                    0   \n",
       "3                                                    0   \n",
       "7                                                    0   \n",
       "8                                                    0   \n",
       "..                                                 ...   \n",
       "450                                                  0   \n",
       "451                                                  0   \n",
       "452                                                  0   \n",
       "453                                                  0   \n",
       "454                                                  0   \n",
       "\n",
       "     Applications: Arts, sports, leisure, travel, and lifestyle  \\\n",
       "0                                                    0            \n",
       "2                                                    0            \n",
       "3                                                    0            \n",
       "7                                                    0            \n",
       "8                                                    0            \n",
       "..                                                 ...            \n",
       "450                                                  0            \n",
       "451                                                  0            \n",
       "452                                                  0            \n",
       "453                                                  0            \n",
       "454                                                  0            \n",
       "\n",
       "     Applications: Broadcasting and media production  \\\n",
       "0                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "7                                                  0   \n",
       "8                                                  0   \n",
       "..                                               ...   \n",
       "450                                                0   \n",
       "451                                                0   \n",
       "452                                                0   \n",
       "453                                                0   \n",
       "454                                                0   \n",
       "\n",
       "     Applications: Business services and analytics  \\\n",
       "0                                                0   \n",
       "2                                                0   \n",
       "3                                                1   \n",
       "7                                                0   \n",
       "8                                                0   \n",
       "..                                             ...   \n",
       "450                                              0   \n",
       "451                                              0   \n",
       "452                                              0   \n",
       "453                                              0   \n",
       "454                                              0   \n",
       "\n",
       "     Applications: Construction and field services  \\\n",
       "0                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "7                                                0   \n",
       "8                                                0   \n",
       "..                                             ...   \n",
       "450                                              0   \n",
       "451                                              0   \n",
       "452                                              0   \n",
       "453                                              0   \n",
       "454                                              0   \n",
       "\n",
       "     Applications: Consumer goods  Applications: Education  \\\n",
       "0                               0                        0   \n",
       "2                               0                        0   \n",
       "3                               0                        0   \n",
       "7                               0                        0   \n",
       "8                               0                        0   \n",
       "..                            ...                      ...   \n",
       "450                             0                        0   \n",
       "451                             0                        0   \n",
       "452                             0                        0   \n",
       "453                             0                        0   \n",
       "454                             0                        0   \n",
       "\n",
       "     Applications: Energy and utilities  ...    BERT_topic5    BERT_topic6  \\\n",
       "0                                     0  ...   1.493676e-01   7.192617e-02   \n",
       "2                                     0  ...  1.251081e-308   1.000000e+00   \n",
       "3                                     0  ...   1.766464e-02   3.240372e-02   \n",
       "7                                     0  ...   3.692844e-02   5.720213e-02   \n",
       "8                                     0  ...  2.029906e-308  2.304330e-308   \n",
       "..                                  ...  ...            ...            ...   \n",
       "450                                   0  ...   6.847546e-02   3.780430e-02   \n",
       "451                                   0  ...   1.031788e-01   5.254648e-02   \n",
       "452                                   0  ...   1.205962e-01   6.213679e-02   \n",
       "453                                   0  ...   1.266922e-01   7.054527e-02   \n",
       "454                                   0  ...   7.311128e-02   3.800437e-02   \n",
       "\n",
       "       BERT_topic7  enacted_binary  gov_category_consolidated_blue_state  \\\n",
       "0     1.225086e-01               0                                     0   \n",
       "2    1.897701e-308               1                                     0   \n",
       "3     3.911828e-02               0                                     1   \n",
       "7     6.529173e-02               1                                     1   \n",
       "8     1.000000e+00               1                                     1   \n",
       "..             ...             ...                                   ...   \n",
       "450   9.176968e-02               1                                     0   \n",
       "451   1.384755e-01               1                                     0   \n",
       "452   1.266515e-01               1                                     0   \n",
       "453   1.175328e-01               1                                     0   \n",
       "454   9.262109e-02               1                                     0   \n",
       "\n",
       "     gov_category_consolidated_federal_executive  \\\n",
       "0                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "7                                              0   \n",
       "8                                              0   \n",
       "..                                           ...   \n",
       "450                                            0   \n",
       "451                                            0   \n",
       "452                                            0   \n",
       "453                                            0   \n",
       "454                                            0   \n",
       "\n",
       "     gov_category_consolidated_federal_legislative  \\\n",
       "0                                                1   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "7                                                0   \n",
       "8                                                0   \n",
       "..                                             ...   \n",
       "450                                              1   \n",
       "451                                              1   \n",
       "452                                              1   \n",
       "453                                              1   \n",
       "454                                              1   \n",
       "\n",
       "     gov_category_consolidated_purple_state  \\\n",
       "0                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "7                                         0   \n",
       "8                                         0   \n",
       "..                                      ...   \n",
       "450                                       0   \n",
       "451                                       0   \n",
       "452                                       0   \n",
       "453                                       0   \n",
       "454                                       0   \n",
       "\n",
       "     gov_category_consolidated_red_state  datedummy  \n",
       "0                                      0       1627  \n",
       "2                                      1       1985  \n",
       "3                                      0       1460  \n",
       "7                                      0       2057  \n",
       "8                                      0       1962  \n",
       "..                                   ...        ...  \n",
       "450                                    0       1050  \n",
       "451                                    0       1050  \n",
       "452                                    0       1050  \n",
       "453                                    0       1050  \n",
       "454                                    0       1050  \n",
       "\n",
       "[401 rows x 94 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Most recent activity date'], errors='ignore')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7daea16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primarily applies to the private sector</th>\n",
       "      <th>Applications: Agriculture and resource extraction</th>\n",
       "      <th>Applications: Arts, sports, leisure, travel, and lifestyle</th>\n",
       "      <th>Applications: Broadcasting and media production</th>\n",
       "      <th>Applications: Business services and analytics</th>\n",
       "      <th>Applications: Construction and field services</th>\n",
       "      <th>Applications: Consumer goods</th>\n",
       "      <th>Applications: Education</th>\n",
       "      <th>Applications: Energy and utilities</th>\n",
       "      <th>Applications: Finance and investment</th>\n",
       "      <th>...</th>\n",
       "      <th>BERT_topic4</th>\n",
       "      <th>BERT_topic5</th>\n",
       "      <th>BERT_topic6</th>\n",
       "      <th>BERT_topic7</th>\n",
       "      <th>enacted_binary</th>\n",
       "      <th>gov_category_consolidated_blue_state</th>\n",
       "      <th>gov_category_consolidated_federal_legislative</th>\n",
       "      <th>gov_category_consolidated_purple_state</th>\n",
       "      <th>gov_category_consolidated_red_state</th>\n",
       "      <th>datedummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.718589e-02</td>\n",
       "      <td>1.493676e-01</td>\n",
       "      <td>7.192617e-02</td>\n",
       "      <td>1.225086e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.261265e-308</td>\n",
       "      <td>1.251081e-308</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.897701e-308</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.199923e-01</td>\n",
       "      <td>1.766464e-02</td>\n",
       "      <td>3.240372e-02</td>\n",
       "      <td>3.911828e-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.148070e-01</td>\n",
       "      <td>3.692844e-02</td>\n",
       "      <td>5.720213e-02</td>\n",
       "      <td>6.529173e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.104355e-308</td>\n",
       "      <td>2.029906e-308</td>\n",
       "      <td>2.304330e-308</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.702525e-02</td>\n",
       "      <td>6.847546e-02</td>\n",
       "      <td>3.780430e-02</td>\n",
       "      <td>9.176968e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.121321e-02</td>\n",
       "      <td>1.031788e-01</td>\n",
       "      <td>5.254648e-02</td>\n",
       "      <td>1.384755e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.821957e-02</td>\n",
       "      <td>1.205962e-01</td>\n",
       "      <td>6.213679e-02</td>\n",
       "      <td>1.266515e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.611540e-02</td>\n",
       "      <td>1.266922e-01</td>\n",
       "      <td>7.054527e-02</td>\n",
       "      <td>1.175328e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.726283e-02</td>\n",
       "      <td>7.311128e-02</td>\n",
       "      <td>3.800437e-02</td>\n",
       "      <td>9.262109e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Primarily applies to the private sector  \\\n",
       "0                                          0   \n",
       "2                                          0   \n",
       "3                                          1   \n",
       "7                                          0   \n",
       "8                                          0   \n",
       "..                                       ...   \n",
       "450                                        0   \n",
       "451                                        0   \n",
       "452                                        0   \n",
       "453                                        0   \n",
       "454                                        0   \n",
       "\n",
       "     Applications: Agriculture and resource extraction  \\\n",
       "0                                                    0   \n",
       "2                                                    0   \n",
       "3                                                    0   \n",
       "7                                                    0   \n",
       "8                                                    0   \n",
       "..                                                 ...   \n",
       "450                                                  0   \n",
       "451                                                  0   \n",
       "452                                                  0   \n",
       "453                                                  0   \n",
       "454                                                  0   \n",
       "\n",
       "     Applications: Arts, sports, leisure, travel, and lifestyle  \\\n",
       "0                                                    0            \n",
       "2                                                    0            \n",
       "3                                                    0            \n",
       "7                                                    0            \n",
       "8                                                    0            \n",
       "..                                                 ...            \n",
       "450                                                  0            \n",
       "451                                                  0            \n",
       "452                                                  0            \n",
       "453                                                  0            \n",
       "454                                                  0            \n",
       "\n",
       "     Applications: Broadcasting and media production  \\\n",
       "0                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "7                                                  0   \n",
       "8                                                  0   \n",
       "..                                               ...   \n",
       "450                                                0   \n",
       "451                                                0   \n",
       "452                                                0   \n",
       "453                                                0   \n",
       "454                                                0   \n",
       "\n",
       "     Applications: Business services and analytics  \\\n",
       "0                                                0   \n",
       "2                                                0   \n",
       "3                                                1   \n",
       "7                                                0   \n",
       "8                                                0   \n",
       "..                                             ...   \n",
       "450                                              0   \n",
       "451                                              0   \n",
       "452                                              0   \n",
       "453                                              0   \n",
       "454                                              0   \n",
       "\n",
       "     Applications: Construction and field services  \\\n",
       "0                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "7                                                0   \n",
       "8                                                0   \n",
       "..                                             ...   \n",
       "450                                              0   \n",
       "451                                              0   \n",
       "452                                              0   \n",
       "453                                              0   \n",
       "454                                              0   \n",
       "\n",
       "     Applications: Consumer goods  Applications: Education  \\\n",
       "0                               0                        0   \n",
       "2                               0                        0   \n",
       "3                               0                        0   \n",
       "7                               0                        0   \n",
       "8                               0                        0   \n",
       "..                            ...                      ...   \n",
       "450                             0                        0   \n",
       "451                             0                        0   \n",
       "452                             0                        0   \n",
       "453                             0                        0   \n",
       "454                             0                        0   \n",
       "\n",
       "     Applications: Energy and utilities  Applications: Finance and investment  \\\n",
       "0                                     0                                     0   \n",
       "2                                     0                                     0   \n",
       "3                                     0                                     1   \n",
       "7                                     0                                     0   \n",
       "8                                     0                                     0   \n",
       "..                                  ...                                   ...   \n",
       "450                                   0                                     0   \n",
       "451                                   0                                     0   \n",
       "452                                   0                                     0   \n",
       "453                                   0                                     0   \n",
       "454                                   0                                     0   \n",
       "\n",
       "     ...    BERT_topic4    BERT_topic5    BERT_topic6    BERT_topic7  \\\n",
       "0    ...   7.718589e-02   1.493676e-01   7.192617e-02   1.225086e-01   \n",
       "2    ...  2.261265e-308  1.251081e-308   1.000000e+00  1.897701e-308   \n",
       "3    ...   8.199923e-01   1.766464e-02   3.240372e-02   3.911828e-02   \n",
       "7    ...   1.148070e-01   3.692844e-02   5.720213e-02   6.529173e-02   \n",
       "8    ...  4.104355e-308  2.029906e-308  2.304330e-308   1.000000e+00   \n",
       "..   ...            ...            ...            ...            ...   \n",
       "450  ...   3.702525e-02   6.847546e-02   3.780430e-02   9.176968e-02   \n",
       "451  ...   5.121321e-02   1.031788e-01   5.254648e-02   1.384755e-01   \n",
       "452  ...   6.821957e-02   1.205962e-01   6.213679e-02   1.266515e-01   \n",
       "453  ...   6.611540e-02   1.266922e-01   7.054527e-02   1.175328e-01   \n",
       "454  ...   3.726283e-02   7.311128e-02   3.800437e-02   9.262109e-02   \n",
       "\n",
       "     enacted_binary  gov_category_consolidated_blue_state  \\\n",
       "0                 0                                     0   \n",
       "2                 1                                     0   \n",
       "3                 0                                     1   \n",
       "7                 1                                     1   \n",
       "8                 1                                     1   \n",
       "..              ...                                   ...   \n",
       "450               1                                     0   \n",
       "451               1                                     0   \n",
       "452               1                                     0   \n",
       "453               1                                     0   \n",
       "454               1                                     0   \n",
       "\n",
       "     gov_category_consolidated_federal_legislative  \\\n",
       "0                                                1   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "7                                                0   \n",
       "8                                                0   \n",
       "..                                             ...   \n",
       "450                                              1   \n",
       "451                                              1   \n",
       "452                                              1   \n",
       "453                                              1   \n",
       "454                                              1   \n",
       "\n",
       "     gov_category_consolidated_purple_state  \\\n",
       "0                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "7                                         0   \n",
       "8                                         0   \n",
       "..                                      ...   \n",
       "450                                       0   \n",
       "451                                       0   \n",
       "452                                       0   \n",
       "453                                       0   \n",
       "454                                       0   \n",
       "\n",
       "     gov_category_consolidated_red_state  datedummy  \n",
       "0                                      0       1627  \n",
       "2                                      1       1985  \n",
       "3                                      0       1460  \n",
       "7                                      0       2057  \n",
       "8                                      0       1962  \n",
       "..                                   ...        ...  \n",
       "450                                    0       1050  \n",
       "451                                    0       1050  \n",
       "452                                    0       1050  \n",
       "453                                    0       1050  \n",
       "454                                    0       1050  \n",
       "\n",
       "[401 rows x 92 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Annotated?', 'Number of segments created'], errors='ignore')\n",
    "# Drop the 'federal_executive' dummy to use as baseline\n",
    "if 'gov_category_consolidated_federal_executive' in df.columns:\n",
    "    df = df.drop(columns=['gov_category_consolidated_federal_executive'])\n",
    "# Drop primarily applies to the government (dummy with private secotr)\n",
    "if 'Primarily applies to the government' in df.columns:\n",
    "    df = df.drop(columns=['Primarily applies to the government'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "bb8297d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear regression excluding all of the content-related columns:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         enacted_binary   R-squared:                       0.528\n",
      "Model:                            OLS   Adj. R-squared:                  0.511\n",
      "Method:                 Least Squares   F-statistic:                     30.87\n",
      "Date:                Thu, 29 May 2025   Prob (F-statistic):           1.91e-54\n",
      "Time:                        12:38:57   Log-Likelihood:                -136.32\n",
      "No. Observations:                 401   AIC:                             302.6\n",
      "Df Residuals:                     386   BIC:                             362.5\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================================\n",
      "                                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "const                                             2.1859      0.204     10.714      0.000       1.785       2.587\n",
      "Primarily applies to the private sector          -0.3197      0.069     -4.647      0.000      -0.455      -0.184\n",
      "BERT_topic0                                       0.1908      0.171      1.117      0.265      -0.145       0.527\n",
      "BERT_topic1                                      -0.3135      0.232     -1.352      0.177      -0.769       0.143\n",
      "BERT_topic2                                      -0.2939      0.174     -1.685      0.093      -0.637       0.049\n",
      "BERT_topic3                                      -0.0861      0.176     -0.488      0.626      -0.433       0.261\n",
      "BERT_topic4                                      -0.4381      0.176     -2.487      0.013      -0.784      -0.092\n",
      "BERT_topic5                                      -0.3624      0.175     -2.072      0.039      -0.706      -0.018\n",
      "BERT_topic6                                      -0.3919      0.174     -2.249      0.025      -0.735      -0.049\n",
      "BERT_topic7                                      -0.3894      0.174     -2.244      0.025      -0.730      -0.048\n",
      "gov_category_consolidated_blue_state             -0.2954      0.119     -2.483      0.013      -0.529      -0.061\n",
      "gov_category_consolidated_federal_legislative    -0.7793      0.108     -7.197      0.000      -0.992      -0.566\n",
      "gov_category_consolidated_purple_state           -0.3349      0.143     -2.344      0.020      -0.616      -0.054\n",
      "gov_category_consolidated_red_state              -0.0697      0.128     -0.543      0.587      -0.322       0.183\n",
      "datedummy                                        -0.0006   4.82e-05    -11.439      0.000      -0.001      -0.000\n",
      "==============================================================================\n",
      "Omnibus:                        0.242   Durbin-Watson:                   0.840\n",
      "Prob(Omnibus):                  0.886   Jarque-Bera (JB):                0.367\n",
      "Skew:                          -0.011   Prob(JB):                        0.832\n",
      "Kurtosis:                       2.854   Cond. No.                     4.84e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.84e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# Define y and X\n",
    "y = df['enacted_binary']\n",
    "\n",
    "# Drop y and any non-numeric columns from X\n",
    "X = df.drop(columns=['enacted_binary'])\n",
    "\n",
    "# Ensure all data is numeric and no object dtype remains\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "y = pd.to_numeric(y, errors='coerce')\n",
    "\n",
    "# # Fit a simple linear regression model\n",
    "# X_with_const = sm.add_constant(X)\n",
    "# model = sm.OLS(y, X_with_const, missing='drop')\n",
    "# results = model.fit()\n",
    "# print(results.summary())\n",
    "\n",
    "# # Print columns with |t| > 2 (excluding the constant)\n",
    "# t_stats = results.tvalues.drop('const', errors='ignore')\n",
    "# cols_over_2 = t_stats[abs(t_stats) > 2].index.tolist()\n",
    "# print(\"Columns with |t| > 2:\")\n",
    "# for col in cols_over_2:\n",
    "#     print(col)\n",
    "\n",
    "# Run a linear regression excluding columns that start with 'Strategies' or 'Applications'\n",
    "exclude_prefixes = ('Strategies', 'Applications', 'Risk factors', 'Incentives', 'Harms')\n",
    "cols_to_exclude = [col for col in X.columns if col.startswith(exclude_prefixes)]\n",
    "X_no_strat_app = X.drop(columns=cols_to_exclude, errors='ignore')\n",
    "\n",
    "# Add constant and fit the model\n",
    "X_no_strat_app_const = sm.add_constant(X_no_strat_app)\n",
    "model_no_strat_app = sm.OLS(y, X_no_strat_app_const, missing='drop')\n",
    "results_no_strat_app = model_no_strat_app.fit()\n",
    "print(\"\\nLinear regression excluding all of the content-related columns:\")\n",
    "print(results_no_strat_app.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ed3c15cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.318874\n",
      "         Iterations 8\n",
      "\n",
      "Logit regression excluding all of the content-related columns, with interaction terms for datedummy on all gov_category vars:\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:         enacted_binary   No. Observations:                  401\n",
      "Model:                          Logit   Df Residuals:                      386\n",
      "Method:                           MLE   Df Model:                           14\n",
      "Date:                Thu, 29 May 2025   Pseudo R-squ.:                  0.5331\n",
      "Time:                        12:46:37   Log-Likelihood:                -127.87\n",
      "converged:                       True   LL-Null:                       -273.89\n",
      "Covariance Type:            nonrobust   LLR p-value:                 5.396e-54\n",
      "=================================================================================================================\n",
      "                                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "const                                            15.0823      2.328      6.478      0.000      10.519      19.645\n",
      "Primarily applies to the private sector          -3.8887      0.859     -4.529      0.000      -5.571      -2.206\n",
      "BERT_topic0                                       1.0761      1.515      0.710      0.477      -1.893       4.045\n",
      "BERT_topic1                                      -0.8131      3.005     -0.271      0.787      -6.703       5.077\n",
      "BERT_topic2                                      -1.8058      1.608     -1.123      0.262      -4.958       1.347\n",
      "BERT_topic3                                      -0.8878      1.692     -0.525      0.600      -4.204       2.429\n",
      "BERT_topic4                                      -3.4418      1.595     -2.158      0.031      -6.568      -0.316\n",
      "BERT_topic5                                      -2.7043      1.803     -1.500      0.134      -6.238       0.829\n",
      "BERT_topic6                                      -3.3581      1.742     -1.928      0.054      -6.772       0.056\n",
      "BERT_topic7                                      -3.0868      1.717     -1.798      0.072      -6.452       0.278\n",
      "gov_category_consolidated_blue_state             -2.1842      1.249     -1.748      0.080      -4.633       0.265\n",
      "gov_category_consolidated_federal_legislative    -6.1960      1.230     -5.035      0.000      -8.608      -3.784\n",
      "gov_category_consolidated_purple_state           -2.8287      1.357     -2.085      0.037      -5.488      -0.170\n",
      "gov_category_consolidated_red_state               0.3159      1.550      0.204      0.838      -2.721       3.353\n",
      "datedummy                                        -0.0053      0.001     -7.649      0.000      -0.007      -0.004\n",
      "=================================================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.355539\n",
      "         Iterations 8\n",
      "\n",
      "Logit regression using only significant variables (p < 0.05):\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:         enacted_binary   No. Observations:                  401\n",
      "Model:                          Logit   Df Residuals:                      392\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Thu, 29 May 2025   Pseudo R-squ.:                  0.4795\n",
      "Time:                        12:46:37   Log-Likelihood:                -142.57\n",
      "converged:                       True   LL-Null:                       -273.89\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.606e-52\n",
      "=================================================================================================================\n",
      "                                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "const                                            14.7277      1.614      9.124      0.000      11.564      17.891\n",
      "Primarily applies to the private sector          -3.8486      0.837     -4.599      0.000      -5.489      -2.209\n",
      "BERT_topic4                                      -2.7703      0.866     -3.200      0.001      -4.467      -1.074\n",
      "BERT_topic6                                      -2.6584      0.900     -2.953      0.003      -4.423      -0.894\n",
      "BERT_topic7                                      -2.2990      0.880     -2.613      0.009      -4.023      -0.575\n",
      "gov_category_consolidated_blue_state             -2.3177      0.921     -2.516      0.012      -4.123      -0.512\n",
      "gov_category_consolidated_federal_legislative    -6.2447      0.885     -7.058      0.000      -7.979      -4.511\n",
      "gov_category_consolidated_purple_state           -3.0611      1.008     -3.036      0.002      -5.037      -1.085\n",
      "datedummy                                        -0.0054      0.001     -8.313      0.000      -0.007      -0.004\n",
      "=================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Add interaction terms between 'datedummy' and all gov_category variables\n",
    "import re\n",
    "\n",
    "logit_model = sm.Logit(y, X_no_strat_app_const, missing='drop')\n",
    "logit_results = logit_model.fit()\n",
    "print(\"\\nLogit regression excluding all of the content-related columns, with interaction terms for datedummy on all gov_category vars:\")\n",
    "print(logit_results.summary())\n",
    "\n",
    "# Identify significant variables (p < 0.05) from the previous logit regression\n",
    "signif_vars = logit_results.pvalues[logit_results.pvalues < 0.1].index.tolist()\n",
    "# Remove 'const' if present\n",
    "signif_vars = [var for var in signif_vars if var != 'const']\n",
    "\n",
    "if signif_vars:\n",
    "    X_signif = sm.add_constant(X_no_strat_app[signif_vars])\n",
    "    logit_model_signif = sm.Logit(y, X_signif, missing='drop')\n",
    "    logit_results_signif = logit_model_signif.fit()\n",
    "    print(\"\\nLogit regression using only significant variables (p < 0.05):\")\n",
    "    print(logit_results_signif.summary())\n",
    "else:\n",
    "    print(\"No significant variables (p < 0.05) found in the previous logit regression.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3691ee89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
